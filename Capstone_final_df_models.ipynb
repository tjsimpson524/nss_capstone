{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cc32e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89436275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nss_capstone/df_rebuild.csv').drop(columns = 'Unnamed: 0').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2d7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val_21_22 = df.loc[(df['Date'] <= '2022-06-16') & (df['Date'] >= '2021-10-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa2a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_07_20 = df.drop(df.index[0:2646])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f8e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_07_20.to_csv('../nss_capstone/df_train_07_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123dd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val_21_22.to_csv('../nss_capstone/df_val_21_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b812a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[(df['Date'] <= '2021-07-01') & (df['Date'] >= '2007-10-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2306a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[['ML','ML_pct','Open Total', 'Close Total', 'Open Spread', 'Close Spread']] = df_train[['ML','ML_pct','Open Total', 'Close Total', 'Open Spread', 'Close Spread']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ae466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['ML_pct'] = df_train['ML_pct'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66f4bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../nss_capstone/df_train_07_20.csv').drop(columns = 'Unnamed: 0').fillna('')\n",
    "df_val = pd.read_csv('../nss_capstone/df_val_21_22.csv').drop(columns = 'Unnamed: 0').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c9eb3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ML'] = df_train['ML'].astype(str)\n",
    "df_train['ML_pct'] = df_train['ML_pct'].astype(str)\n",
    "df_train['Open Spread'] = df_train['Open Spread'].astype(str)\n",
    "df_train['Close Spread'] = df_train['Close Spread'].astype(str)\n",
    "df_train['Open Total'] = df_train['Open Total'].astype(str)\n",
    "df_train['Close Total'] = df_train['Close Total'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e853523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['ML'] = df_val['ML'].astype(str)\n",
    "df_val['ML_pct'] = df_val['ML_pct'].astype(str)\n",
    "df_val['Open Spread'] = df_val['Open Spread'].astype(str)\n",
    "df_val['Close Spread'] = df_val['Close Spread'].astype(str)\n",
    "df_val['Open Total'] = df_val['Open Total'].astype(str)\n",
    "df_val['Close Total'] = df_val['Close Total'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bf203707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Color column\n",
    "df_train['ML'] = le.fit_transform(df_train['ML'])\n",
    "\n",
    "df_train['ML_pct'] = le.fit_transform(df_train['ML_pct'])\n",
    "df_train['Open Spread'] = le.fit_transform(df_train['Open Spread'])\n",
    "df_train['Close Spread'] = le.fit_transform(df_train['Close Spread'])\n",
    "df_train['Open Total'] = le.fit_transform(df_train['Open Total'])\n",
    "df_train['Close Total'] = le.fit_transform(df_train['Close Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b12bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Color column\n",
    "df_val['ML'] = le.fit_transform(df_val['ML'])\n",
    "\n",
    "df_val['ML_pct'] = le.fit_transform(df_val['ML_pct'])\n",
    "df_val['Open Spread'] = le.fit_transform(df_val['Open Spread'])\n",
    "df_val['Close Spread'] = le.fit_transform(df_val['Close Spread'])\n",
    "df_val['Open Total'] = le.fit_transform(df_val['Open Total'])\n",
    "df_val['Close Total'] = le.fit_transform(df_val['Close Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5420b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2236 entries, 0 to 2235\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   game_id       2236 non-null   int64 \n",
      " 1   Date          2236 non-null   object\n",
      " 2   VH            2236 non-null   object\n",
      " 3   Team          2236 non-null   object\n",
      " 4   Final         2236 non-null   int64 \n",
      " 5   ML            2236 non-null   int32 \n",
      " 6   ML_pct        2236 non-null   int32 \n",
      " 7   Open Total    2236 non-null   int32 \n",
      " 8   Close Total   2236 non-null   int32 \n",
      " 9   Open Spread   2236 non-null   int32 \n",
      " 10  Close Spread  2236 non-null   int32 \n",
      " 11  W/L_fav       2236 non-null   int64 \n",
      " 12  W/L_dog       2236 non-null   int64 \n",
      " 13  ATS_fav       2236 non-null   int64 \n",
      " 14  W/L_H_fav     2236 non-null   int64 \n",
      " 15  W/L_V_fav     2236 non-null   int64 \n",
      " 16  W/L_H_dog     2236 non-null   int64 \n",
      " 17  W/L_V_dog     2236 non-null   int64 \n",
      " 18  ATS_H_fav     2236 non-null   int64 \n",
      " 19  ATS_V_fav     2236 non-null   int64 \n",
      " 20  ATS_H_dog     2236 non-null   int64 \n",
      " 21  ATS_V_dog     2236 non-null   int64 \n",
      " 22  Push          2236 non-null   int64 \n",
      " 23  W/L_bool      2236 non-null   int64 \n",
      "dtypes: int32(6), int64(15), object(3)\n",
      "memory usage: 367.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val.info()#.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fafb7",
   "metadata": {},
   "source": [
    "            *******************Gradient Boost***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "441fe71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.32     11463\n",
      "           1       0.32      0.80      0.45      5201\n",
      "\n",
      "    accuracy                           0.39     16664\n",
      "   macro avg       0.51      0.51      0.39     16664\n",
      "weighted avg       0.58      0.39      0.36     16664\n",
      "\n",
      "Accuracy: 0.3931829092654825\n",
      "Confusion Matrix:\n",
      "[[2367 9096]\n",
      " [1016 4185]]\n"
     ]
    }
   ],
   "source": [
    "variables = ['ML', 'Close Total', 'Close Spread']#'Open Total','Open Spread', \n",
    "\n",
    "# Subset your DataFrame with the selected variables\n",
    "X = df_train[variables]\n",
    "y = df_train['W/L_bool']\n",
    "\n",
    "# Group by 'game_id'\n",
    "grouped = df.groupby('game_id')\n",
    "\n",
    "# Initialize train and test indices\n",
    "train_indices, test_indices = [], []\n",
    "\n",
    "# Iterate through groups and split indices\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_indices = [index for index in group_indices if index in df.index]  # Filter out invalid indices\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "# Select the corresponding rows from X and y for training and testing\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "# Fit the GradientBoostingClassifier\n",
    "gbr = GradientBoostingClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, gbr.predict(X_test)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "501d40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.12      0.19      1118\n",
      "           1       0.49      0.85      0.62      1118\n",
      "\n",
      "    accuracy                           0.48      2236\n",
      "   macro avg       0.47      0.48      0.41      2236\n",
      "weighted avg       0.47      0.48      0.41      2236\n",
      "\n",
      "[[136 982]\n",
      " [172 946]]\n"
     ]
    }
   ],
   "source": [
    "X_val = df_val[variables]\n",
    "y_val = df_val['W/L_bool']\n",
    "\n",
    "y_pred_val = gbr.predict(X_val)\n",
    "\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "# top left = true negative\n",
    "# top right = false positive\n",
    "# bottom left = false negative\n",
    "# bottom right = true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedaf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6104ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.32     11463\n",
      "           1       0.32      0.80      0.45      5201\n",
      "\n",
      "    accuracy                           0.39     16664\n",
      "   macro avg       0.51      0.51      0.39     16664\n",
      "weighted avg       0.58      0.39      0.36     16664\n",
      "\n",
      "Accuracy: 0.3931829092654825\n",
      "Confusion Matrix:\n",
      "[[2367 9096]\n",
      " [1016 4185]]\n"
     ]
    }
   ],
   "source": [
    "variables = ['ML', 'Close Total', 'Close Spread']#'Open Total','Open Spread', \n",
    "\n",
    "# Subset your DataFrame with the selected variables\n",
    "X = df_train[variables]\n",
    "y = df_train['W/L_bool']\n",
    "\n",
    "# Group by 'game_id'\n",
    "grouped = df.groupby('game_id')\n",
    "\n",
    "# Initialize train and test indices\n",
    "train_indices, test_indices = [], []\n",
    "\n",
    "# Iterate through groups and split indices\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_indices = [index for index in group_indices if index in df.index]  # Filter out invalid indices\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "# Select the corresponding rows from X and y for training and testing\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "# Fit the GradientBoostingClassifier\n",
    "#gbr = GradientBoostingClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "#rf = RandomForestClassifier(n_estimators=1000)\n",
    "#rf.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, gbr.predict(X_test)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cbb4fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.14      0.20      1118\n",
      "           1       0.48      0.81      0.61      1118\n",
      "\n",
      "    accuracy                           0.47      2236\n",
      "   macro avg       0.45      0.47      0.41      2236\n",
      "weighted avg       0.45      0.47      0.41      2236\n",
      "\n",
      "[[152 966]\n",
      " [213 905]]\n"
     ]
    }
   ],
   "source": [
    "X_val = df_val[variables]\n",
    "y_val = df_val['W/L_bool']\n",
    "\n",
    "#y_pred_val = grb.predict(X_val)\n",
    "#y_pred_val = rf.predict(X_val)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val)\n",
    "\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "# top left = true negative\n",
    "# top right = false positive\n",
    "# bottom left = false negative\n",
    "# bottom right = true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6426d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nss_capstone/df.csv').drop(columns = 'Unnamed: 0').fillna('')\n",
    "\n",
    "\n",
    "variables = ['ML',\n",
    "             'Open Total',\n",
    "             'Open Spread',\n",
    "            'Close Total',\n",
    "            'Close Spread']\n",
    "\n",
    "\n",
    "X = df[variables]\n",
    "y = df['ATS']\n",
    "\n",
    "\n",
    "grouped = df.groupby('game_id')\n",
    "train_indices, test_indices = [], []\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "# top left = true negative\n",
    "# top right = false positive\n",
    "# bottom left = false negative\n",
    "# bottom right = true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc74d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70ac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b15c36fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d8b002de354a03b98b1b1c898ba23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='ML_pct', max=0.99, min=0.5, step=0.01), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.create_histogram(ML_pct)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_histogram(ML_pct):\n",
    "    filtered_df = df_train[df_train['ML_pct'] == ML_pct]\n",
    "    game_counts = filtered_df.shape[0] // 2  # Divide the number of rows by 2 to get the count of games\n",
    "    \n",
    "    win_counts = filtered_df[filtered_df['W/L_bool'] == 1].shape[0]  // 2# Divide the count by 2 for games\n",
    "    loss_counts = filtered_df[filtered_df['W/L_bool'] == 0].shape[0] //2  # Divide the count by 2 for games\n",
    "    \n",
    "#     if game_counts == 0:\n",
    "#         win_ratio = 0\n",
    "#         loss_ratio = 0\n",
    "#     else:\n",
    "    win_ratio = win_counts / game_counts\n",
    "    loss_ratio = loss_counts / game_counts\n",
    "\n",
    "    labels = ['Favorite Wins', 'Underdog Wins']\n",
    "    counts = [win_counts, loss_counts]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(labels, counts)\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('W/L_bool')\n",
    "    plt.title(f'Favorite and Underdog Win Ratios Per Closing Moneyline % = {ML_pct}')\n",
    "    plt.text(max(counts), 0, f'{win_ratio:.2f}', ha='left', va='center')\n",
    "    plt.text(max(counts), 1, f'{loss_ratio:.2f}', ha='left', va='center')\n",
    "    plt.show()\n",
    "\n",
    "interact(create_histogram, ML_pct=widgets.FloatSlider(min=0.5, max=0.99, step=0.01, value=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830c32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
