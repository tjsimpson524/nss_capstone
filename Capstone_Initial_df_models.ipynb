{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d1e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d4f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../nss_capstone/df_rebuild.csv').drop(columns = 'Unnamed: 0').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5e42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val_21_22 = df.loc[(df['Date'] <= '2022-06-16') & (df['Date'] >= '2021-10-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f73ee5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_07_20 = df.drop(df.index[0:2646])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36cea8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_07_20.to_csv('../nss_capstone/df_train_07_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8ac8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val_21_22.to_csv('../nss_capstone/df_val_21_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "686fc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[(df['Date'] <= '2021-07-01') & (df['Date'] >= '2007-10-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f78e1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[['ML','ML_pct','Open Total', 'Close Total', 'Open Spread', 'Close Spread']] = df_train[['ML','ML_pct','Open Total', 'Close Total', 'Open Spread', 'Close Spread']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fe8101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['ML_pct'] = df_train['ML_pct'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef69d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('../nss_capstone/df_train_07_20.csv').drop(columns = 'Unnamed: 0').fillna('')\n",
    "df_val = pd.read_csv('../nss_capstone/df_val_21_22.csv').drop(columns = 'Unnamed: 0').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687088ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ML'] = df_train['ML'].astype(str)\n",
    "df_train['ML_pct'] = df_train['ML_pct'].astype(str)\n",
    "df_train['Open Spread'] = df_train['Open Spread'].astype(str)\n",
    "df_train['Close Spread'] = df_train['Close Spread'].astype(str)\n",
    "df_train['Open Total'] = df_train['Open Total'].astype(str)\n",
    "df_train['Close Total'] = df_train['Close Total'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0ee7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['ML'] = df_val['ML'].astype(str)\n",
    "df_val['ML_pct'] = df_val['ML_pct'].astype(str)\n",
    "df_val['Open Spread'] = df_val['Open Spread'].astype(str)\n",
    "df_val['Close Spread'] = df_val['Close Spread'].astype(str)\n",
    "df_val['Open Total'] = df_val['Open Total'].astype(str)\n",
    "df_val['Close Total'] = df_val['Close Total'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2521fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Color column\n",
    "df_train['ML'] = le.fit_transform(df_train['ML'])\n",
    "\n",
    "df_train['ML_pct'] = le.fit_transform(df_train['ML_pct'])\n",
    "df_train['Open Spread'] = le.fit_transform(df_train['Open Spread'])\n",
    "df_train['Close Spread'] = le.fit_transform(df_train['Close Spread'])\n",
    "df_train['Open Total'] = le.fit_transform(df_train['Open Total'])\n",
    "df_train['Close Total'] = le.fit_transform(df_train['Close Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa321e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Color column\n",
    "df_val['ML'] = le.fit_transform(df_val['ML'])\n",
    "\n",
    "df_val['ML_pct'] = le.fit_transform(df_val['ML_pct'])\n",
    "df_val['Open Spread'] = le.fit_transform(df_val['Open Spread'])\n",
    "df_val['Close Spread'] = le.fit_transform(df_val['Close Spread'])\n",
    "df_val['Open Total'] = le.fit_transform(df_val['Open Total'])\n",
    "df_val['Close Total'] = le.fit_transform(df_val['Close Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01902f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2236, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape#.info()#.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945e01d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_id             0\n",
       "Date                0\n",
       "VH                  0\n",
       "Team                0\n",
       "Final               0\n",
       "ML                  2\n",
       "ML_pct              2\n",
       "Open Total      16668\n",
       "Close Total     16664\n",
       "Open Spread         0\n",
       "Close Spread        0\n",
       "W/L_fav             0\n",
       "W/L_dog             0\n",
       "ATS_fav             0\n",
       "W/L_H_fav           0\n",
       "W/L_V_fav           0\n",
       "W/L_H_dog           0\n",
       "W/L_V_dog           0\n",
       "ATS_H_fav           0\n",
       "ATS_V_fav           0\n",
       "ATS_H_dog           0\n",
       "ATS_V_dog           0\n",
       "Push                0\n",
       "W/L_bool            0\n",
       "Payout              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['ML'].drop.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d31bc",
   "metadata": {},
   "source": [
    "            *******************Gradient Boost***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7fb4a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81     11462\n",
      "           1       0.42      0.03      0.06      5201\n",
      "\n",
      "    accuracy                           0.68     16663\n",
      "   macro avg       0.56      0.51      0.43     16663\n",
      "weighted avg       0.61      0.68      0.57     16663\n",
      "\n",
      "Accuracy: 0.684450579127408\n",
      "Confusion Matrix:\n",
      "[[11250   212]\n",
      " [ 5046   155]]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../nss_capstone/df_train_07_20.csv').drop(columns = 'Unnamed: 0').dropna(subset =['ML'])\n",
    "\n",
    "\n",
    "variables = ['ML','Open Spread', 'Close Spread'] #'Open Total','Open Spread'\n",
    "\n",
    "# Subset your DataFrame with the selected variables\n",
    "X = df_train[variables]\n",
    "y = df_train['W/L_bool']\n",
    "\n",
    "# Group by 'game_id'\n",
    "grouped = df_train.groupby('game_id')\n",
    "\n",
    "# Initialize train and test indices\n",
    "train_indices, test_indices = [], []\n",
    "\n",
    "# Iterate through groups and split indices\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_indices = [index for index in group_indices if index in df_train.index]  # Filter out invalid indices\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "# Select the corresponding rows from X and y for training and testing\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "# Fit the GradientBoostingClassifier\n",
    "gbr = GradientBoostingClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, gbr.predict(X_test)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba1ec33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      1118\n",
      "           1       0.68      0.64      0.66      1118\n",
      "\n",
      "    accuracy                           0.67      2236\n",
      "   macro avg       0.67      0.67      0.67      2236\n",
      "weighted avg       0.67      0.67      0.67      2236\n",
      "\n",
      "[[781 337]\n",
      " [406 712]]\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.read_csv('../nss_capstone/df_val_21_22.csv').drop(columns = 'Unnamed: 0').dropna(subset=['ML'])\n",
    "\n",
    "\n",
    "X_val = df_val[variables]\n",
    "y_val = df_val['W/L_bool']\n",
    "\n",
    "y_pred_val = gbr.predict(X_val)\n",
    "\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf4668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9823d2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.32     11463\n",
      "           1       0.32      0.80      0.45      5201\n",
      "\n",
      "    accuracy                           0.39     16664\n",
      "   macro avg       0.51      0.51      0.39     16664\n",
      "weighted avg       0.58      0.39      0.36     16664\n",
      "\n",
      "Accuracy: 0.3931829092654825\n",
      "Confusion Matrix:\n",
      "[[2367 9096]\n",
      " [1016 4185]]\n"
     ]
    }
   ],
   "source": [
    "variables = ['ML', 'Close Total', 'Close Spread']#'Open Total','Open Spread', \n",
    "\n",
    "# Subset your DataFrame with the selected variables\n",
    "X = df_train[variables]\n",
    "y = df_train['W/L_bool']\n",
    "\n",
    "# Group by 'game_id'\n",
    "grouped = df.groupby('game_id')\n",
    "\n",
    "# Initialize train and test indices\n",
    "train_indices, test_indices = [], []\n",
    "\n",
    "# Iterate through groups and split indices\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_indices = [index for index in group_indices if index in df.index]  # Filter out invalid indices\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "# Select the corresponding rows from X and y for training and testing\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "# Fit the GradientBoostingClassifier\n",
    "#gbr = GradientBoostingClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "#rf = RandomForestClassifier(n_estimators=1000)\n",
    "#rf.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, gbr.predict(X_test)))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "875a70b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.14      0.20      1118\n",
      "           1       0.48      0.81      0.61      1118\n",
      "\n",
      "    accuracy                           0.47      2236\n",
      "   macro avg       0.45      0.47      0.41      2236\n",
      "weighted avg       0.45      0.47      0.41      2236\n",
      "\n",
      "[[152 966]\n",
      " [213 905]]\n"
     ]
    }
   ],
   "source": [
    "X_val = df_val[variables]\n",
    "y_val = df_val['W/L_bool']\n",
    "\n",
    "#y_pred_val = grb.predict(X_val)\n",
    "#y_pred_val = rf.predict(X_val)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val)\n",
    "\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "# top left = true negative\n",
    "# top right = false positive\n",
    "# bottom left = false negative\n",
    "# bottom right = true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fdde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ecfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nss_capstone/df.csv').drop(columns = 'Unnamed: 0').fillna('')\n",
    "\n",
    "\n",
    "variables = ['ML',\n",
    "             'Open Total',\n",
    "             'Open Spread',\n",
    "            'Close Total',\n",
    "            'Close Spread']\n",
    "\n",
    "\n",
    "X = df[variables]\n",
    "y = df['ATS']\n",
    "\n",
    "\n",
    "grouped = df.groupby('game_id')\n",
    "train_indices, test_indices = [], []\n",
    "for _, group_indices in grouped.groups.items():\n",
    "    group_train_indices, group_test_indices = train_test_split(group_indices, test_size=0.2, random_state=321)\n",
    "    train_indices.extend(group_train_indices)\n",
    "    test_indices.extend(group_test_indices)\n",
    "\n",
    "\n",
    "X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "y_train, y_test = y.loc[train_indices], y.loc[test_indices]\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=1000)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "# top left = true negative\n",
    "# top right = false positive\n",
    "# bottom left = false negative\n",
    "# bottom right = true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1562e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbd30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "07689258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d8b002de354a03b98b1b1c898ba23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='ML_pct', max=0.99, min=0.5, step=0.01), Output()), _…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.create_histogram(ML_pct)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_histogram(ML_pct):\n",
    "    filtered_df = df_train[df_train['ML_pct'] == ML_pct]\n",
    "    game_counts = filtered_df.shape[0] // 2  # Divide the number of rows by 2 to get the count of games\n",
    "    \n",
    "    win_counts = filtered_df[filtered_df['W/L_bool'] == 1].shape[0]  // 2# Divide the count by 2 for games\n",
    "    loss_counts = filtered_df[filtered_df['W/L_bool'] == 0].shape[0] //2  # Divide the count by 2 for games\n",
    "    \n",
    "#     if game_counts == 0:\n",
    "#         win_ratio = 0\n",
    "#         loss_ratio = 0\n",
    "#     else:\n",
    "    win_ratio = win_counts / game_counts\n",
    "    loss_ratio = loss_counts / game_counts\n",
    "\n",
    "    labels = ['Favorite Wins', 'Underdog Wins']\n",
    "    counts = [win_counts, loss_counts]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(labels, counts)\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('W/L_bool')\n",
    "    plt.title(f'Favorite and Underdog Win Ratios Per Closing Moneyline % = {ML_pct}')\n",
    "    plt.text(max(counts), 0, f'{win_ratio:.2f}', ha='left', va='center')\n",
    "    plt.text(max(counts), 1, f'{loss_ratio:.2f}', ha='left', va='center')\n",
    "    plt.show()\n",
    "\n",
    "interact(create_histogram, ML_pct=widgets.FloatSlider(min=0.5, max=0.99, step=0.01, value=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8f13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
